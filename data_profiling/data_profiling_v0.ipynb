{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#cimport seaborn as sns\n",
    "\n",
    "from pyspark import  SparkContext\n",
    "from pyspark.sql import SQLContext, HiveContext\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from ProfileSparkDF import ProfileSparkDF\n",
    "\n",
    "import os\n",
    "\n",
    "SPARK_SUBMIT_ARGS = \" --driver-memory 12g --conf spark.akka.threads=32 --conf spark.akka.frameSize=500 --queue datascience.high\"\n",
    "SPARK_SUBMIT_ARGS += \" --conf spark.driver.maxResultSize=0 --conf spark.kryoserializer.buffer.max=2000mb  --executor-memory 20g  pyspark-shell\" \n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] =  SPARK_SUBMIT_ARGS\n",
    "\n",
    "#SPARK_SUBMIT_ARGS = \" --master local[*]\"\n",
    "#SPARK_SUBMIT_ARGS += \" --driver-memory 4g\"\n",
    "#SPARK_SUBMIT_ARGS += \" --executor-memory 4g --num-executors 2\"\n",
    "#SPARK_SUBMIT_ARGS += \" --jars spark_jars/spark-csv_2.10-1.4.0.jar,spark_jars/commons-csv-1.1.jar,spark_jars/univocity-parsers-1.5.1.jar\"\n",
    "#SPARK_SUBMIT_ARGS += \" pyspark-shell\" \n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SPARK_SUBMIT_ARGS\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = HiveContext(sc)\n",
    "#sqlContext = SQLContext(sc)\n",
    "sqlContext.setConf(\"spark.sql.parquet.binaryAsString\", \"true\")\n",
    "sc.setLogLevel(\"INFO\") #ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN\n",
    "print(sc.defaultParallelism, sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = sqlContext.read.parquet(\"/data/raw/vf_it/bss/campaign/2.0/parquet\") #run in cluster\n",
    "df = sqlContext.read.parquet(\"/Users/marquese2/Documents/data/raw_it/bss_campaign/parquet\") #run in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profiler = ProfileSparkDF(df,sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data profiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profiler.df_describe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profiler.get_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
